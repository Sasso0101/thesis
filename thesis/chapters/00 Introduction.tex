\chapter{Introduction}
\label{cha:intro}

Breadth-First Search (BFS) is a fundamental graph traversal algorithm. Its implementations are used in many other algorithms, such as Dijkstra's Algorithm \cite{dijkstra2022note}, the Ford-Fulkerson Method for Maximum Flow \cite{ford1956maximal} and Prim's Algorithm for Minimum Spanning Tree \cite{prim1957shortest}. Due to its popularity, it was also chosen as the kernel of various benchmarks and competitions; for example, it is the primary kernel of the Graph500 competition, which is a rating of supercomputer systems \cite{murphy2010introducing}, and it is part of the GAP benchmark suite \cite{beamer2015gap}, a standard graph processing benchmark suite.

The BFS exploration algorithm takes as input an undirected graph and a \textit{source} node, exploring all of its neighbors before visiting the nodes at the next depth level. The time complexity of BFS is well-known and is typically expressed as \bigO{|V| + |E|}, where $|V|$ represents the number of vertices in the graph and $|E|$ represents the number of edges in the graph (this notation is used consistently throughout the thesis). This is because, in the worst-case scenario, BFS will visit every vertex and traverse every edge in the graph once \cite{cormen2022introduction}. A naive implementation of the Breadth-First Search algorithm using a queue data structure is shown in \Cref{alg:bfs}.

\begin{algorithm}[!b]
    \caption{Breadth-First Search (BFS)}
    \label{alg:bfs}

    % --- Input and Output Definitions ---
    \KwIn{A graph $G=(V, E)$, a source vertex $s \in V$}
    \KwOut{All vertices reachable from $s$ have their distance and parent vertex annotated}
    
    % --- Algorithm Body ---
    \tcc{Initialize all vertices}
    \ForEach{$v \in V$} {
        $v.visited \gets false$\;
        $v.distance \gets \infty$\;
        $v.parent \gets NIL$\;
    }

    \tcc{Initialize the source vertex}
    $s.visited \gets true$\;
    $s.distance \gets 0$\;
    %$s.parent \gets NIL$\;
    
    \tcc{Create a queue for BFS}
    Let $Q$ be a new queue\;
    enqueue($Q, s$)\;

    \tcc{Repeat until the frontier is empty}
    \While{$Q$ is not empty}{
        $u \gets \text{dequeue}(Q)$\;
        \tcc{Remove the vertex from the queue, and check each of its neighbors}
        \ForEach{$v$ in $G.Adj[u]$}{
            \tcc{If the neighbor has not been visited already, mark it as visited, set the parent and the distance, and add it to the queue}
            \If{$v.visited$ is false}{
                $v.visited \gets true$\;
                $v.distance \gets u.distance + 1$\;
                $v.parent \gets u$\;
                enqueue($Q, v$)\;
            }
        }
    }
\end{algorithm}

The principles of graph traversal, exemplified by algorithms like BFS, are central to the field of graph analysis, which has become an essential tool across numerous domains. In social network analysis, for instance, graph algorithms are crucial for understanding community structures \cite{newman2013community}, identifying influential individuals \cite{li2018influence}, and tracking the spread of information \cite{wang2011understanding} or misinformation \cite{cui2020deterrent}. Bioinformatics also heavily depends on graph analysis to model complex biological systems \cite{yi2022graph}. In logistics and transportation, graphs are used to model road networks \cite{thomson1995graph}, flight paths \cite{ozdemir2001flight}, and supply chains \cite{wagner2010assessing}. Furthermore, the rise of machine learning has opened up new frontiers for graph analysis \cite{chami2022machine}. Graph-based machine learning models are now used for a variety of tasks, including recommendation systems that suggest products or connections \cite{gao2023survey}, fraud detection by identifying unusual patterns in transaction networks \cite{pourhabibi2020fraud}, and in the field of natural language processing to understand the relationships between words and concepts \cite{wu2023graph}. For graph analysis to be truly effective across diverse fields, it must operate on extremely large datasets comprising millions or even billions of nodes and edges. For example, the road network graph of Europe, a common graph used in benchmarks, contains 51 million vertices and 108 million edges\footnote{\url{https://sparse.tamu.edu/DIMACS10/europe_osm}}. This graph alone occupies nearly one gigabyte in its uncompressed form. Such data volumes make processing computationally and memory intensive. To efficiently handle these massive datasets, it is crucial to employ modern computational approaches like parallel computing.

Parallel computing is a computation method where multiple processors or computers work together to solve a common problem. The main goal of parallel computing is to increase performance by breaking down large tasks into smaller subtasks that can be executed simultaneously. A prominent approach in parallel computing is the use of multicore processors. A multicore processor is a single chip that contains two or more independent processing units, called cores. Each core can read and execute program instructions independently, allowing for the parallel processing of multiple tasks.

Two primary methods exist for programming on multicore processors: manual parallelization and framework-based parallelization. Manual parallelization requires the programmer to manage threads directly using low-level libraries, such as pthreads. This includes the explicit creation of threads and the usage of synchronization primitives to ensure correct concurrent execution. Alternatively, a parallelization framework such as OpenMP \cite{dagum1998openmp} allows the programmer to insert directives into the code. These directives identify sections that can be executed in parallel, offloading the tasks of thread creation, management, and synchronization to the compiler. This model greatly simplifies the parallelization of certain structures, such as for loops, but the introduced level of abstraction can add some performance overhead when an algorithm’s structure does not align well with the framework’s parallelization model. In such cases, an explicitly-parallelized implementation may be necessary to achieve superior performance. The parallelization of the Breadth-First Search algorithm, detailed in \cref{sec:pthreads}, serves as a case study for this limitation.

Another important aspect to consider when optimizing a program is the memory access pattern. Modern computer architectures feature a hierarchical memory model designed to bridge the speed gap between the fast processor registers and the slower main memory (RAM). This system mitigates the latency difference between processor registers and RAM by using multiple levels of caches, such as L1, L2, and L3. Caches are smaller and faster than RAM and are physically closer to the processor cores. The effectiveness of caching relies on the principles of temporal and spatial locality. Temporal locality is the observation that a program is likely to access a specific data location again shortly after its initial access. Caches exploit this by storing recently used data, so subsequent requests are served from the faster cache rather than the slower main memory. Spatial locality is the principle that a program is likely to access memory locations near a recently accessed address. To leverage this, data is fetched from RAM into the cache in contiguous blocks called cache lines, making subsequent accesses to adjacent data faster.

Breadth-First Search processes each vertex a single time, which unfortunately nullifies performance benefits from temporal locality as data is generally not reused often. Significant performance improvements may be achieved by exploiting spatial locality instead. One way of accomplishing this is by structuring the program to load a vertex and its neighbors into memory simultaneously. A data structure that exploits this approach to improve cache utilization is presented in \cref{sec:mergedcsr}.

In \cref{cha:results}, a comprehensive analysis is conducted to evaluate the proposed implementations on a diverse range of datasets and hardware. This includes an x86 AMD server-grade processor, the emerging open-source RISC-V architecture, and the specialized ARM-based NVIDIA Grace Hopper superchip.

The RISC-V architecture represents a significant shift in processor design. Originating from research at the University of California, Berkeley, RISC-V is an open-source instruction set architecture (ISA) \cite{asanovic2014instruction}. Unlike proprietary ISAs from companies like Intel and AMD, RISC-V is freely available for anyone to use, modify, and build upon without paying licensing fees. This open nature has made it a compelling platform for both academic research and commercial development \cite{mezger2022survey}. Given its unique characteristics and growing importance, it therefore provides a valuable point of comparison for software optimization.

The NVIDIA Grace Hopper superchip is specifically designed for high-performance computing (HPC) and artificial intelligence (AI). This platform integrates a high-core-count, ARM-based Grace CPU with a powerful Hopper GPU on a single module \cite{elster2022nvidia}. Given its unique architectural approach and its deployment in leading supercomputing systems, the Grace Hopper platform offers an interesting point of comparison for evaluating the performance of memory-bound algorithms on next-generation, ARM-based HPC hardware.